{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0695bbc-b319-4966-bd55-a3b37ca37e23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In this notebook we guide you through an example how to get started with AESTETIK\n",
    "1) Data loading and preprocessing\n",
    "2) Morphology feature extraction\n",
    "3) Training the model\n",
    "4) Spot representations and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d0ce4-f840-4023-bd87-d2802b32f45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62c95f-e529-4107-9a77-d895db5cfffb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf11991-98b8-4f8a-9d18-3236748e9573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "from torchvision import transforms\n",
    "import squidpy as sq\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a1bf7c-9b9c-4ab3-a64f-37768a0c9319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aestetik.utils.utils_morphology import extract_morphology_embeddings\n",
    "from aestetik.utils.utils_transcriptomics import preprocess_adata\n",
    "from aestetik.utils.utils_visualization import visualize\n",
    "from aestetik import AESTETIK\n",
    "AESTETIK.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3cfef-92c9-4645-aac9-bfa24ae14c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# Configure the logging module\n",
    "logging.basicConfig(level=logging.INFO)  # Set the desired logging level\n",
    "logging.getLogger(\"pyvips\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5890fa2-84b5-4d34-b7f9-1e1a776b1962",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data and preprocess\n",
    "We start by loading a sample of the `LIBD brain` dataset. This sample contains spatially resolved transcriptomics data and a corresponding high-resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc36093-02c6-4780-8698-7d2b4e1415cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = \"test_data/151676.png\"\n",
    "adata_in = \"test_data/151676.h5ad\"\n",
    "json_path = \"test_data/151676.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec355f32-e4ff-4584-853f-1826f3d16398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_components = 15\n",
    "spot_diameter_fullres = json.load(open(json_path))[\"spot_diameter_fullres\"]\n",
    "dot_size = json.load(open(json_path))[\"dot_size\"]\n",
    "\n",
    "print(f\"spot_diameter_fullres: {spot_diameter_fullres}\")\n",
    "print(f\"dot_size: {dot_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61df78f-3ab7-404a-baa7-ba6046f18a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(adata_in)\n",
    "#adata = adata[adata.obs.sample(100).index,:] # to speed up, we only select 100 spots.\n",
    "adata = preprocess_adata(adata)\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76717840-93c0-47e6-89e1-31884195ea4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "1) `x_array` and `y_array` contain the spatial coordinates of the spots on the array\n",
    "2) `x_pixel` and `y_pixel`contain the spatial coordinates of the spots in the image\n",
    "3) `ground_truth` - spot annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9b05e-3c35-4e01-ae1f-8e3b6eb35f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d39201-6962-49de-8432-1a8347396349",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract morphology features\n",
    "\n",
    "In this example, we use Inception V3 to extract morphology spot features. For this, we use the last layer with dimension 2048. After that, we apply PCA to reduce the feature dimensions from 2048 to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c425a-41f4-4a2f-97b3-d57bf4492fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = Inception_V3_Weights.DEFAULT\n",
    "morphology_model = inception_v3(weights=weights)\n",
    "morphology_model.fc = torch.nn.Identity()\n",
    "\n",
    "morphology_model.eval()    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "feature_dim = 2048\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                weights.transforms(antialias=True),\n",
    "            ])\n",
    "\n",
    "features_inception_v3 = extract_morphology_embeddings(img_path, \n",
    "                                             morphology_model,\n",
    "                                             x_pixel=adata.obs.y_pixel, \n",
    "                                             y_pixel=adata.obs.x_pixel, \n",
    "                                             spot_diameter=spot_diameter_fullres,\n",
    "                                             device=device,\n",
    "                                             n_components=n_components,\n",
    "                                             feature_dim=feature_dim,\n",
    "                                             preprocess=preprocess,\n",
    "                                             apply_pca=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c953e12-8f67-416f-9e64-5a76692a261b",
   "metadata": {},
   "source": [
    "We store the transcriptomics data in `X_pca_transcriptomics` and morphology data in `X_pca_morphology`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49af1d-145f-4b23-8498-57e32a05453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the transcriptomics modality\n",
    "adata.obsm[\"X_pca_transcriptomics\"] = adata.obsm[\"X_pca\"][:,0:n_components]\n",
    "\n",
    "print(f\"{adata.obsm['X_pca_transcriptomics'].shape[0]} spots x {adata.obsm['X_pca_transcriptomics'].shape[1]} transcriptomics PCA components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6caa35-12e3-4ebe-91ea-2942746ce4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set the morphology modality\n",
    "adata.obsm[\"X_pca_morphology\"] = features_inception_v3[:,0:n_components]\n",
    "\n",
    "print(f\"{adata.obsm['X_pca_morphology'].shape[0]} spots x {adata.obsm['X_pca_morphology'].shape[1]} morphology PCA components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f4145-84e7-43d7-8d7c-5417998553b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b6ec2-32a4-454a-916e-91d31f49621f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In our example, we set the morphology weight to 0 (no morphology contribution) and we refine the clusters in spatial space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b185a-fd09-4852-a797-d7cdcf219f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters =    {'morphology_weight': 0,\n",
    "                 'refine_cluster': True,\n",
    "                 'window_size': 7\n",
    "                }\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0f662-308b-4f20-aa09-614e268c6a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AESTETIK(nCluster=adata.obs.ground_truth.unique().size,\n",
    "                 **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77cc19e-60e7-4cbe-a5a2-d18a0de779b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X=adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920fa62-b74f-4979-8fea-ed237e638400",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute embeddings and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401c698-cd85-4d7e-bc8e-89bd2e816eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(X=adata, cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef8644-c6dc-4d0d-b3f3-bffbdffae399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f15649-629a-41e6-b3cf-e57aabdf6ecc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, spot representations can be found in `adata.obsm[\"AESTETIK\"]` and clusters - in `adata.obs[\"AESTETIK_cluster\"]`. We can visualize the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd649a-3c43-4249-a8e2-e11e8497efa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sq.pl.spatial_scatter(adata, color=[\"ground_truth\", \n",
    "                                    \"X_pca_transcriptomics_cluster\",\n",
    "                                    \"X_pca_morphology_cluster\",\n",
    "                                    \"AESTETIK_cluster\"], size=dot_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603811b6",
   "metadata": {},
   "source": [
    "To analyze the model's performance during training, we can also plot the training loss: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(model=model,\n",
    "          plot_loss=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aestetik-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
